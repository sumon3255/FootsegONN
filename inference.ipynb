{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a737e-7739-419e-8fe0-8d3e93bb2dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\QUMLG\\.conda\\envs\\multi\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing efficientnet-b3...\n",
      "Saved mask for efficientnet-b3 at: D:/sumon/2d_segment/save_masks\\masks_b3\\0828_mask.png\n",
      "Processing efficientnet-b4...\n",
      "Saved mask for efficientnet-b4 at: D:/sumon/2d_segment/save_masks\\masks_b4\\0828_mask.png\n",
      "Processing efficientnet-b5...\n",
      "Saved mask for efficientnet-b5 at: D:/sumon/2d_segment/save_masks\\masks_b5\\0828_mask.png\n",
      "All masks saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "#pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths to images and models\n",
    "image_path = \"D:/sumon/2d_segment/content/Data _foot/Test/fold_1/images/0828.PNG\"\n",
    "save_root = \"D:/sumon/2d_segment/save_masks\"\n",
    "\n",
    "# Model files and corresponding save directories\n",
    "models_info = {\n",
    "    \"efficientnet-b3\": {\n",
    "        \"pt_file\": \"D:/sumon/2d_segment/content/ResultsFootUlcer/efficientnet-b3_SelfONN_FPN/efficientnet-b3_SelfONN_FPN_fold_1.pt\",\n",
    "        \"save_folder\": os.path.join(save_root, \"masks_b3\"),\n",
    "    },\n",
    "    \"efficientnet-b4\": {\n",
    "        \"pt_file\": \"D:/sumon/2d_segment/content/ResultsFootUlcer/efficientnet-b4_SelfONN_FPN/efficientnet-b4_SelfONN_FPN_fold_1.pt\",\n",
    "        \"save_folder\": os.path.join(save_root, \"masks_b4\"),\n",
    "    },\n",
    "    \"efficientnet-b5\": {\n",
    "        \"pt_file\": \"D:/sumon/2d_segment/content/ResultsFootUlcer/efficientnet-b5_SelfONN_FPN/efficientnet-b5_SelfONN_FPN_fold_1.pt\",\n",
    "        \"save_folder\": os.path.join(save_root, \"masks_b5\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ensure all save directories exist\n",
    "for model_name, info in models_info.items():\n",
    "    os.makedirs(info[\"save_folder\"], exist_ok=True)\n",
    "\n",
    "# Load the grayscale image\n",
    "image = Image.open(image_path).convert('L')  # Ensure grayscale mode\n",
    "\n",
    "# Convert to NumPy array and normalize\n",
    "gray_image = np.array(image, dtype=np.float32) / 255.0  # Normalize pixel values\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.40936773], std=[0.33767385])\n",
    "])\n",
    "\n",
    "# Convert to tensor and add batch dimension\n",
    "input_tensor = transform(image).unsqueeze(0)  # Shape: [1, 1, 512, 512]\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "# Iterate through models\n",
    "for model_name, info in models_info.items():\n",
    "    print(f\"Processing {model_name}...\")\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(info[\"pt_file\"], map_location=device)\n",
    "\n",
    "    # Define the model architecture correctly\n",
    "    # model = smp.FPN(encoder_name=model_name, classes=1, activation=None)\n",
    "    model = checkpoint['model']\n",
    "    # Load model weights\n",
    "    # if 'model' in checkpoint:\n",
    "    #     model.load_state_dict(checkpoint['model'])\n",
    "    # else:\n",
    "    #     model.load_state_dict(checkpoint)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)  # Shape: [1, 1, 512, 512]\n",
    "        output_cpu = torch.sigmoid(output).squeeze().cpu().numpy()  # Apply sigmoid activation\n",
    "\n",
    "    # Apply threshold to create a binary mask\n",
    "    threshold = 0.5\n",
    "    binary_mask = (output_cpu > threshold).astype(np.uint8) * 255  # Convert to 0-255\n",
    "\n",
    "    # Convert NumPy array to grayscale PIL Image\n",
    "    binary_mask_img = Image.fromarray(binary_mask)  # Ensure grayscale\n",
    "\n",
    "    # Extract image name without extension\n",
    "    img_name = os.path.basename(image_path).split('.')[0]\n",
    "\n",
    "    # Save the mask\n",
    "    save_path = os.path.join(info[\"save_folder\"], f\"{img_name}_mask.png\")\n",
    "    binary_mask_img.save(save_path)\n",
    "\n",
    "    print(f\"Saved mask for {model_name} at: {save_path}\")\n",
    "\n",
    "print( \"All masks saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df536b00-6b2c-4948-a075-863155e187e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing STAPLE consensus:  50%|█████████         | 1/2 [00:00<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consensus range for 0828_mask.png: min=0.0, max=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing STAPLE consensus: 100%|█████████████████| 2/2 [17:19<00:00, 519.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consensus range for 0855_mask.png: min=0.0, max=0.36023546608267554\n",
      "✅ STAPLE consensus masks saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_staple_consensus(mask_paths):\n",
    "    \"\"\"\n",
    "    Calculate the STAPLE consensus for binary masks.\n",
    "\n",
    "    Parameters:\n",
    "    - mask_paths: List of paths to the binary mask images.\n",
    "\n",
    "    Returns:\n",
    "    - consensus_mask: Binary image representing the STAPLE consensus.\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the masks and convert them to binary (0 and 1)\n",
    "    masks = [sitk.ReadImage(mask_path, sitk.sitkUInt8) for mask_path in mask_paths]\n",
    "    \n",
    "    # Normalize masks from [0, 255] to [0, 1] (STAPLE requires binary input)\n",
    "    masks = [sitk.Cast(m > 127, sitk.sitkUInt8) for m in masks]  # Any value >127 becomes 1\n",
    "\n",
    "    # Calculate the STAPLE consensus\n",
    "    staple_filter = sitk.STAPLEImageFilter()\n",
    "    consensus_mask = staple_filter.Execute(masks)\n",
    "\n",
    "    return consensus_mask\n",
    "\n",
    "# Define the output directory\n",
    "out_dir = r'D:\\sumon\\2d_segment\\save_masks\\combined_mask'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Define the folders containing masks\n",
    "mask_folders = [\n",
    "    r'D:\\sumon\\2d_segment\\save_masks\\masks_b3',\n",
    "    r'D:\\sumon\\2d_segment\\save_masks\\masks_b4',\n",
    "    r'D:\\sumon\\2d_segment\\save_masks\\masks_b5'\n",
    "]\n",
    "\n",
    "# Choose a reference folder (for matching filenames)\n",
    "reference_folder = mask_folders[0]\n",
    "\n",
    "# Process each image in the reference folder\n",
    "for image_filename in tqdm(os.listdir(reference_folder), desc='Processing STAPLE consensus'):\n",
    "    mask_paths = [os.path.join(folder, image_filename) for folder in mask_folders]\n",
    "\n",
    "    # Ensure all mask files exist\n",
    "    if not all(os.path.exists(mask_path) for mask_path in mask_paths):\n",
    "        print(f\"Skipping {image_filename} as not all masks are present.\")\n",
    "        continue\n",
    "\n",
    "    # Compute STAPLE consensus\n",
    "    consensus = calculate_staple_consensus(mask_paths)\n",
    "\n",
    "    # Convert STAPLE output to numpy array and check the value range\n",
    "    consensus_array = sitk.GetArrayFromImage(consensus)\n",
    "    print(f\"Consensus range for {image_filename}: min={consensus_array.min()}, max={consensus_array.max()}\")\n",
    "\n",
    "    # Apply threshold to create a binary mask\n",
    "    threshold_filter = sitk.BinaryThresholdImageFilter()\n",
    "    threshold_filter.SetLowerThreshold(0.3)  # Adjust threshold if needed\n",
    "    threshold_filter.SetUpperThreshold(1.0)\n",
    "    threshold_filter.SetInsideValue(1)\n",
    "    threshold_filter.SetOutsideValue(0)\n",
    "    binary_consensus = threshold_filter.Execute(consensus)\n",
    "\n",
    "    # Convert binary mask back to 0-255 range for saving\n",
    "    binary_consensus = sitk.Cast(binary_consensus * 255, sitk.sitkUInt8)\n",
    "\n",
    "    # Save the consensus mask\n",
    "    save_path = os.path.join(out_dir, image_filename)\n",
    "    sitk.WriteImage(binary_consensus, save_path)\n",
    "\n",
    "print(\"✅ STAPLE consensus masks saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9623dc-25a6-4b54-a806-b039abb53298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
